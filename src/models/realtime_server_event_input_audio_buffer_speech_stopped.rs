/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.3.0
 *
 * Generated by: https://github.com/swagger-api/swagger-codegen.git
 */

/// RealtimeServerEventInputAudioBufferSpeechStopped : Returned in `server_vad` mode when the server detects the end of speech in  the audio buffer. The server will also send an `conversation.item.created`  event with the user message item that is created from the audio buffer.

#[allow(unused_imports)]
use serde_json::Value;

#[derive(Debug, Serialize, Deserialize)]
pub struct RealtimeServerEventInputAudioBufferSpeechStopped {
  /// Milliseconds since the session started when speech stopped. This will  correspond to the end of audio sent to the model, and thus includes the  `min_silence_duration_ms` configured in the Session.
  #[serde(rename = "audio_end_ms")]
  audio_end_ms: i32,
  /// The unique ID of the server event.
  #[serde(rename = "event_id")]
  event_id: String,
  /// The ID of the user message item that will be created.
  #[serde(rename = "item_id")]
  item_id: String,
  /// The event type, must be `input_audio_buffer.speech_stopped`.
  #[serde(rename = "type")]
  _type: String
}
